{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codingercat/machine-learning-projects/blob/main/Project_CaseStudy2_ReviewComments_Shambhavi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<hr style = \"height : 2px; background-color: blue;\">\n",
        "<center> <h1> BASIC CERTIFICATION COURSE IN ARTIFICIAL INTELLIGENCE </h1></center>\n",
        "<center> <h2> Case Study 2 </h2></center>\n",
        "<center> <h2> Review of Consumer Complaints</h2></center>\n",
        "\n",
        "<center>  Submitted by : Shambhavi Thakur</center>\n",
        "<hr style = \"height : 2px; background-color: blue;\">"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "WAnRe0HFYUGU",
        "outputId": "bb5fc8e0-3c96-4185-dc72-2785869da160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<hr style = \"height : 2px; background-color: blue;\">\n",
              "<center> <h1> BASIC CERTIFICATION COURSE IN ARTIFICIAL INTELLIGENCE </h1></center>\n",
              "<center> <h2> Case Study 2 </h2></center>\n",
              "<center> <h2> Review of Consumer Complaints</h2></center>\n",
              "\n",
              "<center>  Submitted by : Shambhavi Thakur</center>\n",
              "<hr style = \"height : 2px; background-color: blue;\">\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Objective : This code make use of complaint data against financial companies to perform following tasks on the data\n",
        "    1. Create Topic models to classify comlplaints in various categories.\n",
        "    2. We will do test preprcessingw here which remove all token which belong to org and other preprocessing\n",
        "    3. We will try out two Topic Modelling Algorithms\n",
        "        1. Latent Dirichtlet ALogorithm - In my exp does not work well on short text data\n",
        "        2. Non Negative Matrix factorisation"
      ],
      "metadata": {
        "id": "YgYiqYyzlI7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### About the Dataset\n",
        "The dataset comprises of Consumer Complaints on Financial products and weâ€™ll see how to classify consumer complaints text into these categories: Debt collection, Consumer Loan, Mortgage, Credit card, Credit reporting, Student loan, Bank account or service, Payday loan, Money transfers, Other financial service, Prepaid card.\n",
        "Also we will try to identify the companies from the dataset"
      ],
      "metadata": {
        "id": "fkAbIw7QlI7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import the required package"
      ],
      "metadata": {
        "id": "VpPuAGfIlI7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import nltk\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from nltk.stem import PorterStemmer\n",
        "import string"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:34.403475Z",
          "iopub.execute_input": "2023-06-22T06:18:34.403942Z",
          "iopub.status.idle": "2023-06-22T06:18:37.393584Z",
          "shell.execute_reply.started": "2023-06-22T06:18:34.403898Z",
          "shell.execute_reply": "2023-06-22T06:18:37.392412Z"
        },
        "trusted": true,
        "id": "Phhkphk4lI7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the complaints data csv"
      ],
      "metadata": {
        "id": "6XxsNuX_lI7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complaint_data = pd.read_csv(\"../input/consumer-complaints-financial-products/Consumer_Complaints.csv\",low_memory = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:37.395985Z",
          "iopub.execute_input": "2023-06-22T06:18:37.396351Z",
          "iopub.status.idle": "2023-06-22T06:18:44.014781Z",
          "shell.execute_reply.started": "2023-06-22T06:18:37.396317Z",
          "shell.execute_reply": "2023-06-22T06:18:44.013413Z"
        },
        "trusted": true,
        "id": "H-rCGrSslI7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "06d1fa51-c95d-46f5-b949-6a83f173fe01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-801fbd412da0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplaint_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/consumer-complaints-financial-products/Consumer_Complaints.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/consumer-complaints-financial-products/Consumer_Complaints.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert the columns names so that they don't have space and are more readable\n",
        "complaint_data.columns = [i.lower().replace(\" \",\"_\").replace(\"-\",\"_\") for i in complaint_data.columns]\n",
        "complaint_data.columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:44.016862Z",
          "iopub.execute_input": "2023-06-22T06:18:44.017284Z",
          "iopub.status.idle": "2023-06-22T06:18:44.030465Z",
          "shell.execute_reply.started": "2023-06-22T06:18:44.017232Z",
          "shell.execute_reply": "2023-06-22T06:18:44.029220Z"
        },
        "trusted": true,
        "id": "REqE3C_zlI7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets understand the shape an dtypes of the data"
      ],
      "metadata": {
        "id": "HViFke7xlI7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The shape of data is \",complaint_data.shape)\n",
        "print (\"The data types for our data are as follows \")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:44.032003Z",
          "iopub.execute_input": "2023-06-22T06:18:44.032428Z",
          "iopub.status.idle": "2023-06-22T06:18:44.045031Z",
          "shell.execute_reply.started": "2023-06-22T06:18:44.032390Z",
          "shell.execute_reply": "2023-06-22T06:18:44.043813Z"
        },
        "trusted": true,
        "id": "S84ZTfZ7lI7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### All the varables are text - which may correspond to categories and other variables\n",
        "print (\" The number of unique values in each column is as follows\")\n",
        "### Lets do a describe with including objects\n",
        "complaint_data.describe(include = 'object').T.reset_index()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:44.049904Z",
          "iopub.execute_input": "2023-06-22T06:18:44.050329Z",
          "iopub.status.idle": "2023-06-22T06:18:47.965709Z",
          "shell.execute_reply.started": "2023-06-22T06:18:44.050292Z",
          "shell.execute_reply": "2023-06-22T06:18:47.964681Z"
        },
        "trusted": true,
        "id": "OzVgLbrhlI7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######  From above description we see that only 114704 rows have complaint text and as we are interested in only those row which have complaint text. We wll drop all rows where complaint narrative is na"
      ],
      "metadata": {
        "id": "1-66OgvKlI7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Keep only the consumer complaints is not null\n",
        "complaint_data = complaint_data[~complaint_data['consumer_complaint_narrative'].isna()]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:47.968060Z",
          "iopub.execute_input": "2023-06-22T06:18:47.968463Z",
          "iopub.status.idle": "2023-06-22T06:18:48.115120Z",
          "shell.execute_reply.started": "2023-06-22T06:18:47.968427Z",
          "shell.execute_reply": "2023-06-22T06:18:48.114156Z"
        },
        "trusted": true,
        "id": "CKBiKMMplI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Create a distirbution of length of customers complaints. We have very left skew in length of complaints\n",
        "### Which is expected as most compalints can be written in less than 500 words\n",
        "complaint_data['consumer_complaint_narrative'].apply(len).plot(kind = 'hist')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:48.116698Z",
          "iopub.execute_input": "2023-06-22T06:18:48.117404Z",
          "iopub.status.idle": "2023-06-22T06:18:48.503397Z",
          "shell.execute_reply.started": "2023-06-22T06:18:48.117351Z",
          "shell.execute_reply": "2023-06-22T06:18:48.501919Z"
        },
        "trusted": true,
        "id": "nbEbRf1FlI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Keep the length columns as a new column\n",
        "complaint_data['comp_length'] = complaint_data['consumer_complaint_narrative'].apply(len)\n",
        "complaint_data.reset_index(inplace = True)\n",
        "complaint_data['consumer_complaint_narrative'] = complaint_data['consumer_complaint_narrative'].str.replace(r\"XX+\\s\",\"\")\n",
        "complaint_data['consumer_complaint_narrative'] = complaint_data['consumer_complaint_narrative'].str.replace(\"XXXX\",\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:48.505141Z",
          "iopub.execute_input": "2023-06-22T06:18:48.505550Z",
          "iopub.status.idle": "2023-06-22T06:18:49.799498Z",
          "shell.execute_reply.started": "2023-06-22T06:18:48.505516Z",
          "shell.execute_reply": "2023-06-22T06:18:49.797932Z"
        },
        "trusted": true,
        "id": "CA724FPJlI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complaint_data = complaint_data.sample(frac = 0.5,random_state = 5)\n",
        "complaint_data.reset_index(inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:49.802094Z",
          "iopub.execute_input": "2023-06-22T06:18:49.802643Z",
          "iopub.status.idle": "2023-06-22T06:18:49.883039Z",
          "shell.execute_reply.started": "2023-06-22T06:18:49.802600Z",
          "shell.execute_reply": "2023-06-22T06:18:49.881393Z"
        },
        "trusted": true,
        "id": "u4cqLq1olI7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We will first craete the data processing pipeline to do cleaning on the data"
      ],
      "metadata": {
        "id": "mL97Dj3ZlI7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "stop_words = nlp.Defaults.stop_words\n",
        "\n",
        "symbols = \" \".join(string.punctuation).split(\" \")\n",
        "\n",
        "ps = PorterStemmer()\n",
        "import re\n",
        "\n",
        "def cleanup_text(docs,logging = False):\n",
        "    texts = []\n",
        "    counter = 1\n",
        "    for doc in docs:\n",
        "\n",
        "        if counter % 5000 == 0 :\n",
        "            print (\"Processed %d of out of %d documents\"% (counter,len(docs)))\n",
        "        counter += 1\n",
        "\n",
        "        doc = nlp(doc)\n",
        "\n",
        "\n",
        "        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != \"-PRON-\"]\n",
        "\n",
        "        tokens =[tok for tok in tokens if tok not in symbols]\n",
        "        tokens = [tok for tok in tokens if tok not in stop_words]\n",
        "        tokens = [re.sub('[0-9]', '', i) for i in tokens]\n",
        "        tokens = ' '.join(tokens)\n",
        "        texts.append(tokens)\n",
        "    return (pd.Series(texts))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:39:46.397622Z",
          "iopub.execute_input": "2023-06-22T07:39:46.397983Z",
          "iopub.status.idle": "2023-06-22T07:39:48.372108Z",
          "shell.execute_reply.started": "2023-06-22T07:39:46.397950Z",
          "shell.execute_reply": "2023-06-22T07:39:48.371092Z"
        },
        "trusted": true,
        "id": "85PLIFiFlI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complaint_data['comp_preprocessed'] = cleanup_text(complaint_data['consumer_complaint_narrative'])"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-06-22T06:18:51.480318Z",
          "iopub.execute_input": "2023-06-22T06:18:51.480708Z",
          "iopub.status.idle": "2023-06-22T06:56:15.918526Z",
          "shell.execute_reply.started": "2023-06-22T06:18:51.480672Z",
          "shell.execute_reply": "2023-06-22T06:56:15.916983Z"
        },
        "trusted": true,
        "id": "qcg0vrTolI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Shape of data before removing NA's ,\",complaint_data.shape)\n",
        "complaint_data =complaint_data[~complaint_data['comp_preprocessed'].isna()]\n",
        "print (\"Shape of data before removing NA's ,\",complaint_data.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:56:15.920528Z",
          "iopub.execute_input": "2023-06-22T06:56:15.920924Z",
          "iopub.status.idle": "2023-06-22T06:56:16.015279Z",
          "shell.execute_reply.started": "2023-06-22T06:56:15.920888Z",
          "shell.execute_reply": "2023-06-22T06:56:16.013885Z"
        },
        "trusted": true,
        "id": "PhEl1eoelI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complaint_data[['comp_preprocessed','consumer_complaint_narrative']].head(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:56:16.017010Z",
          "iopub.execute_input": "2023-06-22T06:56:16.017675Z",
          "iopub.status.idle": "2023-06-22T06:56:16.038046Z",
          "shell.execute_reply.started": "2023-06-22T06:56:16.017627Z",
          "shell.execute_reply": "2023-06-22T06:56:16.036041Z"
        },
        "trusted": true,
        "id": "-v7A14lJlI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets Create the piprle line for NMF models\n",
        "from time import time\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "#####################  Let extract from act the features from the dataset #####################\n",
        "\n",
        "print (\"Extracting the tf-idf features form NMF\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df = 0.5, min_df = 5, max_features = 500, ngram_range = (1,4))\n",
        "\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(complaint_data['comp_preprocessed'])\n",
        "print (\"done in %0.3fs.\" % (time() - t0))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:56:16.039833Z",
          "iopub.execute_input": "2023-06-22T06:56:16.040348Z",
          "iopub.status.idle": "2023-06-22T06:57:32.371007Z",
          "shell.execute_reply.started": "2023-06-22T06:56:16.040303Z",
          "shell.execute_reply": "2023-06-22T06:57:32.369610Z"
        },
        "trusted": true,
        "id": "oHo4kMkTlI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################### Now we will fit model for 10 diff values of clusters #####################\n",
        "n_comp = [10,20,30,40,50,60,70,80,90,100,110]\n",
        "loss = []\n",
        "for comps in n_comp:\n",
        "\n",
        "    t0 = time()\n",
        "    nmf = NMF(n_components = comps, random_state = 1, beta_loss = 'kullback-leibler',solver = 'mu',max_iter = 200,\n",
        "             alpha = 0.1, l1_ratio = 0.5).fit(tfidf)\n",
        "    loss.append(nmf.reconstruction_err_)\n",
        "    print (\"done in %0.3f \" % (time() -t0))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T06:57:32.373089Z",
          "iopub.execute_input": "2023-06-22T06:57:32.373615Z",
          "iopub.status.idle": "2023-06-22T07:34:40.119734Z",
          "shell.execute_reply.started": "2023-06-22T06:57:32.373565Z",
          "shell.execute_reply": "2023-06-22T07:34:40.118169Z"
        },
        "trusted": true,
        "id": "w2C-K8hwlI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################### Let try to create a elbow and find out the best model clusters #####################\n",
        "plt.plot(loss)\n",
        "plt.xlabel('Number of Topics')\n",
        "plt.ylabel('Reconstruction Error - Frobenius Norm')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:34:40.122018Z",
          "iopub.execute_input": "2023-06-22T07:34:40.122495Z",
          "iopub.status.idle": "2023-06-22T07:34:40.316057Z",
          "shell.execute_reply.started": "2023-06-22T07:34:40.122452Z",
          "shell.execute_reply": "2023-06-22T07:34:40.314640Z"
        },
        "trusted": true,
        "id": "fb6FJ2jglI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a function which goes through - topic * word matrix and extract the top keywords"
      ],
      "metadata": {
        "id": "n9JjS9hXlI7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:34:40.318182Z",
          "iopub.execute_input": "2023-06-22T07:34:40.319217Z",
          "iopub.status.idle": "2023-06-22T07:34:40.330728Z",
          "shell.execute_reply.started": "2023-06-22T07:34:40.319150Z",
          "shell.execute_reply": "2023-06-22T07:34:40.329040Z"
        },
        "trusted": true,
        "id": "QtBF0yC-lI7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_top_words(nmf, tfidf_vectorizer.get_feature_names(), 10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:34:40.333946Z",
          "iopub.execute_input": "2023-06-22T07:34:40.334465Z",
          "iopub.status.idle": "2023-06-22T07:34:40.393018Z",
          "shell.execute_reply.started": "2023-06-22T07:34:40.334414Z",
          "shell.execute_reply": "2023-06-22T07:34:40.391980Z"
        },
        "trusted": true,
        "id": "2DNL6Fg-lI7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:34:40.394474Z",
          "iopub.execute_input": "2023-06-22T07:34:40.394821Z",
          "iopub.status.idle": "2023-06-22T07:34:40.401521Z",
          "shell.execute_reply.started": "2023-06-22T07:34:40.394789Z",
          "shell.execute_reply": "2023-06-22T07:34:40.400499Z"
        },
        "trusted": true,
        "id": "d97Dlz-clI7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################### Now we will fit model for 10 diff values of clusters #####################\n",
        "n_comp = [10,20,30,40,50]\n",
        "\n",
        "for comps in n_comp:\n",
        "    loss1 = []\n",
        "    t0 = time()\n",
        "    lda = LatentDirichletAllocation(n_components=comps, max_iter=2,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "    lda.fit(tfidf)\n",
        "    print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:34:40.402944Z",
          "iopub.execute_input": "2023-06-22T07:34:40.403343Z",
          "iopub.status.idle": "2023-06-22T07:39:46.353704Z",
          "shell.execute_reply.started": "2023-06-22T07:34:40.403307Z",
          "shell.execute_reply": "2023-06-22T07:39:46.352357Z"
        },
        "trusted": true,
        "id": "JDqo6yI9lI7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_top_words(lda, tfidf_vectorizer.get_feature_names(), 10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-22T07:39:46.355007Z",
          "iopub.execute_input": "2023-06-22T07:39:46.355367Z",
          "iopub.status.idle": "2023-06-22T07:39:46.394697Z",
          "shell.execute_reply.started": "2023-06-22T07:39:46.355333Z",
          "shell.execute_reply": "2023-06-22T07:39:46.392996Z"
        },
        "trusted": true,
        "id": "4U2RSusnlI7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}